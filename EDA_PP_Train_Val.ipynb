{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e80633-35d0-4d55-9189-8396388a0c63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# This notebook contains all the EDA, Feature Engg. , Preprocessing, Training and Analysis of Validation data with evalution metrics and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c4bf67-9782-46a5-ac18-46cdafc2e630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix,ConfusionMatrixDisplay\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7697a868-33bb-4d12-b796-56b18362ec3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# EDA, Feature Engineering, Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b988c0d-c1db-4609-a7c2-384c41047694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6103db55-2018-4323-9932-84536e3ab839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X49</th>\n",
       "      <th>X50</th>\n",
       "      <th>X51</th>\n",
       "      <th>X52</th>\n",
       "      <th>X53</th>\n",
       "      <th>X54</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.342</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.200</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>16.304</td>\n",
       "      <td>148</td>\n",
       "      <td>375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.440</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.46</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.338</td>\n",
       "      <td>123</td>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    X1    X2    X3     X4    X5    X6    X7    X8   X9  ...  X49  \\\n",
       "0           0  0.00  0.00  4.34   0.00  0.00  0.00  0.00  0.00  0.0  ...  0.0   \n",
       "1           1  0.00  0.56  0.56   0.00  1.12  0.56  2.25  0.00  0.0  ...  0.0   \n",
       "2           2  0.00  0.00  0.00   0.00  0.00  0.00  0.00  0.00  0.0  ...  0.0   \n",
       "3           3  0.64  0.00  0.64   0.00  1.93  0.00  0.00  0.00  0.0  ...  0.0   \n",
       "4           4  0.58  0.00  0.00  35.46  0.58  0.00  0.58  0.58  0.0  ...  0.0   \n",
       "\n",
       "     X50  X51    X52    X53    X54     X55  X56  X57  Y  \n",
       "0  0.000  0.0  1.342  0.000  0.000   1.200    2   12  0  \n",
       "1  0.083  0.0  0.503  0.000  0.083  16.304  148  375  1  \n",
       "2  0.000  0.0  0.000  0.000  0.000   1.000    1    5  0  \n",
       "3  0.000  0.0  0.462  0.370  0.000   2.440   22  122  1  \n",
       "4  0.000  0.0  0.239  0.239  0.000   3.338  123  207  1  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() # Checking top values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13867fa2-9b9a-4915-b57c-25a8acf8a748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove Unnamed: 0 columns , possibley because of missing index=False in pd.to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf54f0e-18d1-45fd-8231-84a1839a86ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "611f7d43-1d70-45ed-94ec-68e380298f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X49</th>\n",
       "      <th>X50</th>\n",
       "      <th>X51</th>\n",
       "      <th>X52</th>\n",
       "      <th>X53</th>\n",
       "      <th>X54</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.342</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.200</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>16.304</td>\n",
       "      <td>148</td>\n",
       "      <td>375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.440</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.46</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.338</td>\n",
       "      <td>123</td>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1    X2    X3     X4    X5    X6    X7    X8   X9   X10  ...  X49  \\\n",
       "0  0.00  0.00  4.34   0.00  0.00  0.00  0.00  0.00  0.0  0.00  ...  0.0   \n",
       "1  0.00  0.56  0.56   0.00  1.12  0.56  2.25  0.00  0.0  0.56  ...  0.0   \n",
       "2  0.00  0.00  0.00   0.00  0.00  0.00  0.00  0.00  0.0  0.00  ...  0.0   \n",
       "3  0.64  0.00  0.64   0.00  1.93  0.00  0.00  0.00  0.0  0.00  ...  0.0   \n",
       "4  0.58  0.00  0.00  35.46  0.58  0.00  0.58  0.58  0.0  0.00  ...  0.0   \n",
       "\n",
       "     X50  X51    X52    X53    X54     X55  X56  X57  Y  \n",
       "0  0.000  0.0  1.342  0.000  0.000   1.200    2   12  0  \n",
       "1  0.083  0.0  0.503  0.000  0.083  16.304  148  375  1  \n",
       "2  0.000  0.0  0.000  0.000  0.000   1.000    1    5  0  \n",
       "3  0.000  0.0  0.462  0.370  0.000   2.440   22  122  1  \n",
       "4  0.000  0.0  0.239  0.239  0.000   3.338  123  207  1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e71bec4-dee9-477a-a7aa-6ff154f625ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe many columns have 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89a1aac2-bae9-4c85-ace7-fd2363a8c4fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X49</th>\n",
       "      <th>X50</th>\n",
       "      <th>X51</th>\n",
       "      <th>X52</th>\n",
       "      <th>X53</th>\n",
       "      <th>X54</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.102990</td>\n",
       "      <td>0.206419</td>\n",
       "      <td>0.284419</td>\n",
       "      <td>0.062074</td>\n",
       "      <td>0.311309</td>\n",
       "      <td>0.095974</td>\n",
       "      <td>0.112320</td>\n",
       "      <td>0.106041</td>\n",
       "      <td>0.091146</td>\n",
       "      <td>0.244345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037493</td>\n",
       "      <td>0.139252</td>\n",
       "      <td>0.015876</td>\n",
       "      <td>0.272971</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.043828</td>\n",
       "      <td>5.047150</td>\n",
       "      <td>52.338107</td>\n",
       "      <td>283.059079</td>\n",
       "      <td>0.392327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.296322</td>\n",
       "      <td>1.253828</td>\n",
       "      <td>0.504352</td>\n",
       "      <td>1.369361</td>\n",
       "      <td>0.656195</td>\n",
       "      <td>0.261455</td>\n",
       "      <td>0.389516</td>\n",
       "      <td>0.398694</td>\n",
       "      <td>0.271417</td>\n",
       "      <td>0.667065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235054</td>\n",
       "      <td>0.276309</td>\n",
       "      <td>0.083600</td>\n",
       "      <td>0.858634</td>\n",
       "      <td>0.256991</td>\n",
       "      <td>0.452862</td>\n",
       "      <td>31.397035</td>\n",
       "      <td>204.445218</td>\n",
       "      <td>578.339858</td>\n",
       "      <td>0.488331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.580750</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.263500</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317250</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.714000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.340000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>4.540000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>2.777000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>10062.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                X1           X2           X3           X4           X5  \\\n",
       "count  3910.000000  3910.000000  3910.000000  3910.000000  3910.000000   \n",
       "mean      0.102990     0.206419     0.284419     0.062074     0.311309   \n",
       "std       0.296322     1.253828     0.504352     1.369361     0.656195   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.430000     0.000000     0.387500   \n",
       "max       4.340000    14.280000     4.540000    42.810000     9.090000   \n",
       "\n",
       "                X6           X7           X8           X9          X10  ...  \\\n",
       "count  3910.000000  3910.000000  3910.000000  3910.000000  3910.000000  ...   \n",
       "mean      0.095974     0.112320     0.106041     0.091146     0.244345  ...   \n",
       "std       0.261455     0.389516     0.398694     0.271417     0.667065  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.170000  ...   \n",
       "max       3.570000     7.270000    11.110000     3.230000    18.180000  ...   \n",
       "\n",
       "               X49          X50          X51          X52          X53  \\\n",
       "count  3910.000000  3910.000000  3910.000000  3910.000000  3910.000000   \n",
       "mean      0.037493     0.139252     0.015876     0.272971     0.077820   \n",
       "std       0.235054     0.276309     0.083600     0.858634     0.256991   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.066000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.188000     0.000000     0.317250     0.054000   \n",
       "max       4.385000     9.752000     2.777000    32.478000     6.003000   \n",
       "\n",
       "               X54          X55          X56           X57            Y  \n",
       "count  3910.000000  3910.000000  3910.000000   3910.000000  3910.000000  \n",
       "mean      0.043828     5.047150    52.338107    283.059079     0.392327  \n",
       "std       0.452862    31.397035   204.445218    578.339858     0.488331  \n",
       "min       0.000000     1.000000     1.000000      1.000000     0.000000  \n",
       "25%       0.000000     1.580750     6.000000     35.000000     0.000000  \n",
       "50%       0.000000     2.263500    15.000000     94.000000     0.000000  \n",
       "75%       0.000000     3.714000    43.000000    264.000000     1.000000  \n",
       "max      19.829000  1102.500000  9989.000000  10062.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e234a44f-9d8f-4026-a000-366cd44abc62",
   "metadata": {
    "tags": []
   },
   "source": [
    "`Observe that there are no NaN columns in dataset but many columns have 0 as value even at 75 percentile, these columns also have a very low variance which makes them not a suitable fetaure.\n",
    "\n",
    "We select features with at least 50 precentile value being non-zero`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706ec70c-b32c-45da-8b3b-ee049d5ba713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_desc = data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29d2cb27-6370-4693-91e9-24dc6a87fc35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "select_feat = data_desc.loc['50%'][data_desc.loc['50%']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6822be15-4357-4d9e-a876-7f5e039c4c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X12     0.1400\n",
       "X19     1.3100\n",
       "X21     0.2350\n",
       "X50     0.0660\n",
       "X55     2.2635\n",
       "X56    15.0000\n",
       "X57    94.0000\n",
       "Name: 50%, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b21f6e7-d6a5-441c-bc76-07e2b3d1a6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "select_df = data[['X12', 'X19', 'X21', 'X50', 'X55', 'X56', 'X57','Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7fbea81-26ee-4b3f-8fea-5f1484fa31fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X12</th>\n",
       "      <th>X19</th>\n",
       "      <th>X21</th>\n",
       "      <th>X50</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.553685</td>\n",
       "      <td>1.660939</td>\n",
       "      <td>0.818253</td>\n",
       "      <td>0.139252</td>\n",
       "      <td>5.047150</td>\n",
       "      <td>52.338107</td>\n",
       "      <td>283.059079</td>\n",
       "      <td>0.392327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.876412</td>\n",
       "      <td>1.760214</td>\n",
       "      <td>1.210078</td>\n",
       "      <td>0.276309</td>\n",
       "      <td>31.397035</td>\n",
       "      <td>204.445218</td>\n",
       "      <td>578.339858</td>\n",
       "      <td>0.488331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.580750</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.140000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>2.263500</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>2.637500</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>3.714000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.670000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>10062.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X12          X19          X21          X50          X55  \\\n",
       "count  3910.000000  3910.000000  3910.000000  3910.000000  3910.000000   \n",
       "mean      0.553685     1.660939     0.818253     0.139252     5.047150   \n",
       "std       0.876412     1.760214     1.210078     0.276309    31.397035   \n",
       "min       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     1.580750   \n",
       "50%       0.140000     1.310000     0.235000     0.066000     2.263500   \n",
       "75%       0.820000     2.637500     1.270000     0.188000     3.714000   \n",
       "max       9.670000    18.750000    11.110000     9.752000  1102.500000   \n",
       "\n",
       "               X56           X57            Y  \n",
       "count  3910.000000   3910.000000  3910.000000  \n",
       "mean     52.338107    283.059079     0.392327  \n",
       "std     204.445218    578.339858     0.488331  \n",
       "min       1.000000      1.000000     0.000000  \n",
       "25%       6.000000     35.000000     0.000000  \n",
       "50%      15.000000     94.000000     0.000000  \n",
       "75%      43.000000    264.000000     1.000000  \n",
       "max    9989.000000  10062.000000     1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e796f0df-3245-414a-82d6-fd39d5f70fd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "`We look for outlier values , \n",
    "feature wise and remove some 110 \n",
    "values in total across fetaures \n",
    "X57,X56,X55,X50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aa04765-2408-432f-8337-abb2f20e69e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select_feat = select_feat.sample(frac=1,random_state=72,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b13e5477-c4fa-4aad-a338-5081bd28d96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "select_df_no_outliers = select_df[(select_df.X57 < 3000)]\n",
    "select_df_no_outliers = select_df_no_outliers[select_df_no_outliers.X56 < 1000]\n",
    "select_df_no_outliers = select_df_no_outliers[select_df_no_outliers.X55 < 50]\n",
    "select_df_no_outliers = select_df_no_outliers[select_df_no_outliers.X50 < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b92a921-c894-4246-b91e-7e75d10f1694",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X12</th>\n",
       "      <th>X19</th>\n",
       "      <th>X21</th>\n",
       "      <th>X50</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3793.000000</td>\n",
       "      <td>3793.000000</td>\n",
       "      <td>3793.000000</td>\n",
       "      <td>3793.000000</td>\n",
       "      <td>3793.000000</td>\n",
       "      <td>3793.000000</td>\n",
       "      <td>3793.000000</td>\n",
       "      <td>3793.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.552984</td>\n",
       "      <td>1.675829</td>\n",
       "      <td>0.805009</td>\n",
       "      <td>0.124044</td>\n",
       "      <td>3.160672</td>\n",
       "      <td>40.962826</td>\n",
       "      <td>235.016082</td>\n",
       "      <td>0.385447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.879121</td>\n",
       "      <td>1.768352</td>\n",
       "      <td>1.191685</td>\n",
       "      <td>0.168805</td>\n",
       "      <td>3.201992</td>\n",
       "      <td>89.367040</td>\n",
       "      <td>373.214415</td>\n",
       "      <td>0.486765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.140000</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>2.227000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.810000</td>\n",
       "      <td>2.640000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>3.621000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.670000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>49.866000</td>\n",
       "      <td>887.000000</td>\n",
       "      <td>2923.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X12          X19          X21          X50          X55  \\\n",
       "count  3793.000000  3793.000000  3793.000000  3793.000000  3793.000000   \n",
       "mean      0.552984     1.675829     0.805009     0.124044     3.160672   \n",
       "std       0.879121     1.768352     1.191685     0.168805     3.201992   \n",
       "min       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     1.560000   \n",
       "50%       0.140000     1.320000     0.230000     0.064000     2.227000   \n",
       "75%       0.810000     2.640000     1.250000     0.183000     3.621000   \n",
       "max       9.670000    18.750000    11.110000     0.976000    49.866000   \n",
       "\n",
       "               X56          X57            Y  \n",
       "count  3793.000000  3793.000000  3793.000000  \n",
       "mean     40.962826   235.016082     0.385447  \n",
       "std      89.367040   373.214415     0.486765  \n",
       "min       1.000000     1.000000     0.000000  \n",
       "25%       6.000000    34.000000     0.000000  \n",
       "50%      14.000000    92.000000     0.000000  \n",
       "75%      39.000000   249.000000     1.000000  \n",
       "max     887.000000  2923.000000     1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_df_no_outliers.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4246d3bf-0be7-4b6a-a597-6c8f1e784d29",
   "metadata": {
    "tags": []
   },
   "source": [
    "`Removing these outlier values helps in \n",
    "reducing the value of mean, variance, sd \n",
    "bringing them closer to general distribution of values in selected fetaures and helps the model in generalizing well`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "594ace7e-7434-4380-a9a9-b6cb7a65883a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "select_df_no_outliers = select_df_no_outliers.sample(frac=1,random_state=10,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8758c5d7-a87c-4b0b-a150-91be86070286",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X12</th>\n",
       "      <th>X19</th>\n",
       "      <th>X21</th>\n",
       "      <th>X50</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.578</td>\n",
       "      <td>3.800</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.763</td>\n",
       "      <td>2.285</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.28</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.103</td>\n",
       "      <td>1.403</td>\n",
       "      <td>18</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.526</td>\n",
       "      <td>1.571</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.818</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.473</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>0.67</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.537</td>\n",
       "      <td>2.604</td>\n",
       "      <td>17</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>0.00</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.700</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>0.29</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.086</td>\n",
       "      <td>3.591</td>\n",
       "      <td>37</td>\n",
       "      <td>352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.350</td>\n",
       "      <td>2.608</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3793 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X12   X19   X21    X50    X55  X56  X57  Y\n",
       "0     0.00  0.00  0.00  0.578  3.800   15   19  1\n",
       "1     0.00  0.00  0.00  0.763  2.285   10   16  0\n",
       "2     0.28  1.97  0.00  0.103  1.403   18   80  0\n",
       "3     3.22  0.00  0.00  0.526  1.571    3   11  0\n",
       "4     3.22  0.00  0.00  0.000  1.818    9   20  0\n",
       "...    ...   ...   ...    ...    ...  ...  ... ..\n",
       "3788  0.00  2.32  0.00  0.000  2.473   10   47  0\n",
       "3789  0.67  2.68  0.00  0.537  2.604   17  112  0\n",
       "3790  0.00  4.83  0.00  0.000  1.700    5   17  1\n",
       "3791  0.29  1.16  1.16  0.086  3.591   37  352  1\n",
       "3792  0.00  2.85  0.95  0.350  2.608   14   60  0\n",
       "\n",
       "[3793 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_df_no_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a3ecbe-7e83-4579-8af7-3f8289437d36",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Training and Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29fc31c3-2157-4ff4-a085-2a3b903e87e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=select_df_no_outliers.iloc[:,:-1].values\n",
    "# Normalizing\n",
    "x_scaled = min_max_scaler.fit_transform(X)\n",
    "\n",
    "Y=select_df_no_outliers.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4bac508-7b18-483f-90f2-0c2c8c68b360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(x_scaled, Y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6eed0ce-36e3-4e1e-8ff8-961dd869cb85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Train Samples\n",
      "(3034, 7) (3034,)\n",
      "No. of Val Samples\n",
      "(759,) (759,)\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of Train Samples\")\n",
    "print(X_train.shape , Y_train.shape)\n",
    "print(\"No. of Val Samples\")\n",
    "print(Y_val.shape  , Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "487e02b2-eb50-4630-9d36-4424241ec478",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.06455862977603\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train,Y_train,verbose=True)\n",
    "Y_pred = model.predict(X_val)\n",
    "print(accuracy_score(Y_val,Y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48ebac75-0ae5-445e-8d11-631f74ee0640",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1f982d76bf0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true=Y_val,y_pred=Y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6da247-b714-4c06-82fa-be3561a60612",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### I used optuna library for Hyper Parameter Tuning, below I have commented the code after taking the best HP values and using them for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3ff72bf-54c5-4302-ae6b-83e3efa142a5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-08 01:45:56,370] A new study created in memory with name: no-name-27c60619-d617-4989-a440-64c7ae7d7778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980e1626b599404c9a1ff359b2d8c4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-03-08 01:45:56,648] Trial 0 finished with value: 0.8787878787878788 and parameters: {'learning_rate': 0.0971478715980467, 'max_depth': 4, 'subsample': 0.7014547059045118}. Best is trial 0 with value: 0.8787878787878788.\n",
      "[I 2024-03-08 01:45:56,822] Trial 1 finished with value: 0.8748353096179183 and parameters: {'learning_rate': 0.2713101803854854, 'max_depth': 3, 'subsample': 0.8472407623870454}. Best is trial 0 with value: 0.8787878787878788.\n",
      "[I 2024-03-08 01:45:57,122] Trial 2 finished with value: 0.8945981554677207 and parameters: {'learning_rate': 0.26541706934856457, 'max_depth': 6, 'subsample': 0.8044911519718918}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:45:57,484] Trial 3 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.17299116500411268, 'max_depth': 7, 'subsample': 0.6543594345126755}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:45:57,847] Trial 4 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.21469210825588406, 'max_depth': 7, 'subsample': 0.8723553790005224}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:45:58,005] Trial 5 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.2829176131457909, 'max_depth': 3, 'subsample': 0.9836444376655582}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:45:58,147] Trial 6 finished with value: 0.8722002635046113 and parameters: {'learning_rate': 0.2922217407339521, 'max_depth': 3, 'subsample': 0.6503208256328515}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:45:58,525] Trial 7 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.25729760905930427, 'max_depth': 8, 'subsample': 0.9887942765439718}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:45:58,697] Trial 8 finished with value: 0.8722002635046113 and parameters: {'learning_rate': 0.19740497073673835, 'max_depth': 3, 'subsample': 0.7718251846070902}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:45:59,185] Trial 9 finished with value: 0.8880105401844532 and parameters: {'learning_rate': 0.19477975725879157, 'max_depth': 9, 'subsample': 0.798616637591096}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:45:59,517] Trial 10 finished with value: 0.8669301712779973 and parameters: {'learning_rate': 0.010815957799977183, 'max_depth': 5, 'subsample': 0.9089126344143726}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:45:59,880] Trial 11 finished with value: 0.8906455862977603 and parameters: {'learning_rate': 0.21286068776328892, 'max_depth': 6, 'subsample': 0.8695960248468917}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:00,275] Trial 12 finished with value: 0.8827404479578392 and parameters: {'learning_rate': 0.13242210485436673, 'max_depth': 6, 'subsample': 0.7371066005758237}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:00,693] Trial 13 finished with value: 0.8840579710144928 and parameters: {'learning_rate': 0.2338111710865818, 'max_depth': 7, 'subsample': 0.8988880988235184}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:01,149] Trial 14 finished with value: 0.8880105401844532 and parameters: {'learning_rate': 0.13279721218282683, 'max_depth': 7, 'subsample': 0.8353885919707319}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:01,455] Trial 15 finished with value: 0.8840579710144928 and parameters: {'learning_rate': 0.23227974063765885, 'max_depth': 5, 'subsample': 0.9404319331213511}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:01,975] Trial 16 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.07471102977708788, 'max_depth': 8, 'subsample': 0.6028267011861481}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:02,291] Trial 17 finished with value: 0.8880105401844532 and parameters: {'learning_rate': 0.2508062191483591, 'max_depth': 5, 'subsample': 0.8043902765574678}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:02,779] Trial 18 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.29955659195232637, 'max_depth': 8, 'subsample': 0.7551145847236723}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:03,345] Trial 19 finished with value: 0.8919631093544137 and parameters: {'learning_rate': 0.1705959566171456, 'max_depth': 9, 'subsample': 0.9430569268880034}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:03,707] Trial 20 finished with value: 0.8801054018445322 and parameters: {'learning_rate': 0.21895596985419274, 'max_depth': 6, 'subsample': 0.8721823167813456}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:04,203] Trial 21 finished with value: 0.8787878787878788 and parameters: {'learning_rate': 0.28946401660173915, 'max_depth': 8, 'subsample': 0.7524505420899147}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:04,635] Trial 22 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.297861881883743, 'max_depth': 7, 'subsample': 0.7141539020199587}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:05,100] Trial 23 finished with value: 0.8919631093544137 and parameters: {'learning_rate': 0.254381868633676, 'max_depth': 8, 'subsample': 0.8057981954821616}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:05,540] Trial 24 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.2686417621482409, 'max_depth': 7, 'subsample': 0.776341443130529}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:05,917] Trial 25 finished with value: 0.8919631093544137 and parameters: {'learning_rate': 0.243507240723404, 'max_depth': 6, 'subsample': 0.8461751940030513}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:06,461] Trial 26 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.20001475028728335, 'max_depth': 9, 'subsample': 0.6836128063513975}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:06,940] Trial 27 finished with value: 0.8866930171277997 and parameters: {'learning_rate': 0.2705108688297658, 'max_depth': 8, 'subsample': 0.8257748307512635}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:07,318] Trial 28 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.22251901789755316, 'max_depth': 6, 'subsample': 0.7409682044742792}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:07,586] Trial 29 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.07179524410090324, 'max_depth': 4, 'subsample': 0.7058252465048522}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:07,847] Trial 30 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.179205294312585, 'max_depth': 4, 'subsample': 0.7736005233644125}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:08,413] Trial 31 finished with value: 0.8919631093544137 and parameters: {'learning_rate': 0.1492570361619583, 'max_depth': 9, 'subsample': 0.6787645723865555}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:08,949] Trial 32 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.20760065343475942, 'max_depth': 9, 'subsample': 0.6797659309567676}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:09,443] Trial 33 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.2710072374013066, 'max_depth': 8, 'subsample': 0.604277253496825}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:09,860] Trial 34 finished with value: 0.8880105401844532 and parameters: {'learning_rate': 0.18773588594093887, 'max_depth': 7, 'subsample': 0.6504779876259775}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:10,372] Trial 35 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.23678873883147167, 'max_depth': 8, 'subsample': 0.8697656030731434}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:10,938] Trial 36 finished with value: 0.8866930171277997 and parameters: {'learning_rate': 0.15809015363056184, 'max_depth': 9, 'subsample': 0.7235394074833003}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:11,378] Trial 37 finished with value: 0.8906455862977603 and parameters: {'learning_rate': 0.2795086682098562, 'max_depth': 7, 'subsample': 0.6710498002734154}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:11,914] Trial 38 finished with value: 0.8919631093544137 and parameters: {'learning_rate': 0.26136847639231336, 'max_depth': 9, 'subsample': 0.8200756337048403}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:12,401] Trial 39 finished with value: 0.8866930171277997 and parameters: {'learning_rate': 0.2994665567849633, 'max_depth': 8, 'subsample': 0.6327219581844703}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:12,715] Trial 40 finished with value: 0.8840579710144928 and parameters: {'learning_rate': 0.2004504592495634, 'max_depth': 5, 'subsample': 0.7604729437951415}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:13,218] Trial 41 finished with value: 0.8840579710144928 and parameters: {'learning_rate': 0.2377908309460969, 'max_depth': 8, 'subsample': 0.864452084806246}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:13,658] Trial 42 finished with value: 0.8840579710144928 and parameters: {'learning_rate': 0.22676127259087842, 'max_depth': 7, 'subsample': 0.8852934062130625}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:14,200] Trial 43 finished with value: 0.8919631093544137 and parameters: {'learning_rate': 0.2799522781190085, 'max_depth': 9, 'subsample': 0.922631861813992}. Best is trial 2 with value: 0.8945981554677207.\n",
      "[I 2024-03-08 01:46:14,698] Trial 44 finished with value: 0.8998682476943346 and parameters: {'learning_rate': 0.2457334942364935, 'max_depth': 8, 'subsample': 0.7937190126884546}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:15,137] Trial 45 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.2505337059546819, 'max_depth': 7, 'subsample': 0.7955790523930429}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:15,526] Trial 46 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.250392594883234, 'max_depth': 6, 'subsample': 0.7863848592055198}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:15,971] Trial 47 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.28394266985603944, 'max_depth': 7, 'subsample': 0.795733155704279}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:16,427] Trial 48 finished with value: 0.8906455862977603 and parameters: {'learning_rate': 0.26217854159340026, 'max_depth': 7, 'subsample': 0.8459492632875188}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:16,806] Trial 49 finished with value: 0.8866930171277997 and parameters: {'learning_rate': 0.24682972126445596, 'max_depth': 6, 'subsample': 0.8219655876360831}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:17,215] Trial 50 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.28312791832057405, 'max_depth': 7, 'subsample': 0.9676445238253004}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:17,641] Trial 51 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.2783990813118967, 'max_depth': 7, 'subsample': 0.9535644620397675}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:18,035] Trial 52 finished with value: 0.8880105401844532 and parameters: {'learning_rate': 0.29320817732892795, 'max_depth': 7, 'subsample': 0.9653247616167282}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:18,412] Trial 53 finished with value: 0.8919631093544137 and parameters: {'learning_rate': 0.2644540201874444, 'max_depth': 6, 'subsample': 0.7524675542661777}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:18,900] Trial 54 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.25489332150222166, 'max_depth': 8, 'subsample': 0.9839984126718644}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:19,283] Trial 55 finished with value: 0.8866930171277997 and parameters: {'learning_rate': 0.288366487086561, 'max_depth': 6, 'subsample': 0.9212780064792326}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:19,781] Trial 56 finished with value: 0.8919631093544137 and parameters: {'learning_rate': 0.22136495510733414, 'max_depth': 8, 'subsample': 0.7874010091011536}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:20,221] Trial 57 finished with value: 0.8906455862977603 and parameters: {'learning_rate': 0.2112036081198707, 'max_depth': 7, 'subsample': 0.9987335824218443}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:20,567] Trial 58 finished with value: 0.8840579710144928 and parameters: {'learning_rate': 0.24257210158557813, 'max_depth': 5, 'subsample': 0.7271653371713566}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:21,027] Trial 59 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.2808103064325544, 'max_depth': 8, 'subsample': 0.8128323408603557}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:21,444] Trial 60 finished with value: 0.8761528326745718 and parameters: {'learning_rate': 0.029397974642288133, 'max_depth': 6, 'subsample': 0.7828531479530604}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:21,998] Trial 61 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.23015818134798344, 'max_depth': 9, 'subsample': 0.6958137441213783}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:22,457] Trial 62 finished with value: 0.8840579710144928 and parameters: {'learning_rate': 0.1916860920774004, 'max_depth': 7, 'subsample': 0.8926092573675538}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:22,970] Trial 63 finished with value: 0.8840579710144928 and parameters: {'learning_rate': 0.20568885677060808, 'max_depth': 8, 'subsample': 0.833058845747517}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:23,514] Trial 64 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.27381695363741443, 'max_depth': 9, 'subsample': 0.756379108779927}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:23,954] Trial 65 finished with value: 0.8919631093544137 and parameters: {'learning_rate': 0.21508192755687575, 'max_depth': 7, 'subsample': 0.7956587466254998}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:24,451] Trial 66 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.25847701161021264, 'max_depth': 8, 'subsample': 0.8543451572586631}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:24,946] Trial 67 finished with value: 0.8880105401844532 and parameters: {'learning_rate': 0.2582595207553925, 'max_depth': 8, 'subsample': 0.855274847225696}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:25,449] Trial 68 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.2918121691488979, 'max_depth': 8, 'subsample': 0.8398030751191166}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:25,764] Trial 69 finished with value: 0.8827404479578392 and parameters: {'learning_rate': 0.2718702049822028, 'max_depth': 5, 'subsample': 0.7641560274485967}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:26,285] Trial 70 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.24701907852101973, 'max_depth': 8, 'subsample': 0.8106182048779047}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:26,822] Trial 71 finished with value: 0.8959156785243741 and parameters: {'learning_rate': 0.2346445465350155, 'max_depth': 9, 'subsample': 0.9042213902780836}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:27,233] Trial 72 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.29998765718664294, 'max_depth': 7, 'subsample': 0.8795056934884442}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:27,595] Trial 73 finished with value: 0.8787878787878788 and parameters: {'learning_rate': 0.23510642943293394, 'max_depth': 6, 'subsample': 0.9038393804731082}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:28,075] Trial 74 finished with value: 0.8827404479578392 and parameters: {'learning_rate': 0.26416659516058033, 'max_depth': 8, 'subsample': 0.9155404784572377}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:28,577] Trial 75 finished with value: 0.8880105401844532 and parameters: {'learning_rate': 0.2555661773025435, 'max_depth': 8, 'subsample': 0.8563916440538879}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:29,128] Trial 76 finished with value: 0.8906455862977603 and parameters: {'learning_rate': 0.1260234313784809, 'max_depth': 9, 'subsample': 0.7386025934600035}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:29,545] Trial 77 finished with value: 0.8906455862977603 and parameters: {'learning_rate': 0.24417009234539028, 'max_depth': 7, 'subsample': 0.9623962323778633}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:30,063] Trial 78 finished with value: 0.8866930171277997 and parameters: {'learning_rate': 0.286562691670407, 'max_depth': 9, 'subsample': 0.9432736367679981}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:30,457] Trial 79 finished with value: 0.8866930171277997 and parameters: {'learning_rate': 0.2681635278864022, 'max_depth': 6, 'subsample': 0.9306115078479279}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:30,702] Trial 80 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.22267894378721154, 'max_depth': 3, 'subsample': 0.8301660285943195}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:31,284] Trial 81 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.17607714477219366, 'max_depth': 9, 'subsample': 0.8913086246951348}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:31,834] Trial 82 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.22978383235261937, 'max_depth': 9, 'subsample': 0.8540627206165771}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:32,410] Trial 83 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.23792290633135435, 'max_depth': 9, 'subsample': 0.6285347193167293}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:32,850] Trial 84 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.2518298178620301, 'max_depth': 7, 'subsample': 0.7685515313941628}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:33,362] Trial 85 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.20121493224790438, 'max_depth': 8, 'subsample': 0.800647477644582}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:33,865] Trial 86 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.18405282265048858, 'max_depth': 9, 'subsample': 0.8168066543122074}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:34,359] Trial 87 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.1581998739931908, 'max_depth': 8, 'subsample': 0.8752190381411383}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:34,815] Trial 88 finished with value: 0.8906455862977603 and parameters: {'learning_rate': 0.21727519783743973, 'max_depth': 7, 'subsample': 0.8646880705443976}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:35,314] Trial 89 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.2768900561409608, 'max_depth': 8, 'subsample': 0.8447170177026933}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:35,674] Trial 90 finished with value: 0.8945981554677207 and parameters: {'learning_rate': 0.26358985108234684, 'max_depth': 6, 'subsample': 0.6987986776840251}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:36,046] Trial 91 finished with value: 0.8906455862977603 and parameters: {'learning_rate': 0.25894290306632267, 'max_depth': 6, 'subsample': 0.6873364977804785}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:36,440] Trial 92 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.264829590030659, 'max_depth': 6, 'subsample': 0.702892800171587}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:36,840] Trial 93 finished with value: 0.8840579710144928 and parameters: {'learning_rate': 0.2402168827424736, 'max_depth': 6, 'subsample': 0.6670604062042738}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:37,228] Trial 94 finished with value: 0.8880105401844532 and parameters: {'learning_rate': 0.25157715372482037, 'max_depth': 7, 'subsample': 0.7181152227243599}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:37,616] Trial 95 finished with value: 0.8840579710144928 and parameters: {'learning_rate': 0.29388382481400854, 'max_depth': 6, 'subsample': 0.7764659996027051}. Best is trial 44 with value: 0.8998682476943346.\n",
      "[I 2024-03-08 01:46:38,172] Trial 96 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.22588838191694433, 'max_depth': 9, 'subsample': 0.9735043255129058}. Best is trial 96 with value: 0.9011857707509882.\n",
      "[I 2024-03-08 01:46:38,499] Trial 97 finished with value: 0.8840579710144928 and parameters: {'learning_rate': 0.2849663660874379, 'max_depth': 5, 'subsample': 0.9836984695929739}. Best is trial 96 with value: 0.9011857707509882.\n",
      "[I 2024-03-08 01:46:38,896] Trial 98 finished with value: 0.8880105401844532 and parameters: {'learning_rate': 0.2287145046722247, 'max_depth': 7, 'subsample': 0.9950558563912858}. Best is trial 96 with value: 0.9011857707509882.\n",
      "[I 2024-03-08 01:46:39,447] Trial 99 finished with value: 0.8880105401844532 and parameters: {'learning_rate': 0.2723460379387299, 'max_depth': 9, 'subsample': 0.9653271526969833}. Best is trial 96 with value: 0.9011857707509882.\n",
      "Best hyperparameters: {'learning_rate': 0.22588838191694433, 'max_depth': 9, 'subsample': 0.9735043255129058}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def objective(trial):\n",
    "#     # Define hyperparameters to optimize\n",
    "#     params = {\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "#     }\n",
    "\n",
    "#     tuned_model =xgb.XGBClassifier(**params)\n",
    "#     tuned_model.fit(X_train, Y_train)\n",
    "#     y_pred_tuned = tuned_model.predict(X_val)\n",
    "#     accuracy = accuracy_score(Y_val, y_pred_tuned)\n",
    "#     return accuracy\n",
    "\n",
    "# # Create an Optuna study\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=100,show_progress_bar=True)  # You can adjust the number of trials\n",
    "\n",
    "# # Get the best hyperparameters\n",
    "# best_params = study.best_params\n",
    "# print(f\"Best hyperparameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0327904-32df-4dc4-9d2c-a0473c25d4b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "`best_params : {'learning_rate': 0.22588838191694433,\n",
    " 'max_depth': 9,\n",
    " 'subsample': 0.9735043255129058}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b3aaf-6271-4470-b8e4-4d6f44cb5f5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Model using best parameters as generated by optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "868845be-bf21-44ab-ba7b-91488038d639",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.11857707509881\n"
     ]
    }
   ],
   "source": [
    "model_2 = xgb.XGBClassifier(**best_params)\n",
    "model_2.fit(X_train,Y_train,verbose=True)\n",
    "Y_pred_2 = model_2.predict(X_val)\n",
    "print(accuracy_score(Y_val,Y_pred_2)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d39fe4-a861-4f1e-b0ff-fda754bc3a4e",
   "metadata": {},
   "source": [
    "`We observe an increase in accuracy of model by around 1% after using these hyper parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac867819-7705-4596-a8cc-e44b26469114",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1f983a11d50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_2 = confusion_matrix(y_true=Y_val,y_pred=Y_pred_2)\n",
    "ConfusionMatrixDisplay(cm_2).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "daa6d3d2-c931-47eb-8759-5384174f5ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1f983b96050>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true=Y_val,y_pred=Y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7736e27-61cd-47b0-9602-1107f21e534a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Observations and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4099831e-fbb8-487e-a57b-cc53deee71e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      " Base Model \n",
      "FPR - 8.225 % ; FNR - 15.152\n",
      "----------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       462\n",
      "           1       0.87      0.85      0.86       297\n",
      "\n",
      "    accuracy                           0.89       759\n",
      "   macro avg       0.89      0.88      0.88       759\n",
      "weighted avg       0.89      0.89      0.89       759\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Tuned Model \n",
      "FPR - 7.792 % ; FNR - 13.131\n",
      "----------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       462\n",
      "           1       0.88      0.87      0.87       297\n",
      "\n",
      "    accuracy                           0.90       759\n",
      "   macro avg       0.90      0.90      0.90       759\n",
      "weighted avg       0.90      0.90      0.90       759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*100)\n",
    "print(\" Base Model \")\n",
    "print(f\"FPR - { round((cm[0][1]/(cm[0][1]+cm[0][0]))*100,3)} % ; FNR - { round ((cm[1][0]/(cm[1][0]+cm[1][1]))*100,3)}\")\n",
    "print(\"-\"*100)\n",
    "print(classification_report(y_true=Y_val,y_pred=Y_pred))\n",
    "print(\"-\"*100)\n",
    "print(\" Tuned Model \")\n",
    "print(f\"FPR - { round((cm_2[0][1]/(cm_2[0][1]+cm_2[0][0]))*100,3)} % ; FNR - { round ((cm_2[1][0]/(cm_2[1][0]+cm_2[1][1]))*100,3)}\")\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(classification_report(y_true=Y_val,y_pred=Y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e2fbe1-12f1-4bb2-95a8-e7569dc10100",
   "metadata": {},
   "source": [
    "1. We can clearly observe a 1% increase in overall accuracy \n",
    "2. Class wise we observe 2%(Class:0) and 1%(Class:1) inc. in Precision\n",
    "3. We observe 2%(Class:1) inc. in Recall\n",
    "4. Class wise we observe 1%(Class:0) and 1%(Class:1) inc. in f1-score\n",
    "5. There is sharp decrease of 5.2% in FPR and 15.4% decrease in FNR.\n",
    "6. As the classes are imbalanced, weighted avg which uses the support values of each class gives a better performance metric of the model.\n",
    "7. Here the weighted avg is greater than macro avg which is a positive sign.\n",
    "\n",
    "Hence, we select the model_2 (Tuned Model )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf47c92c-821e-4453-bc97-455164381ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving the best model\n",
    "# model_2.save_model('.model/bestModel.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45091af-4296-40a9-ad15-1e801f2b4f22",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the Tuned model we observe that it has a really good precision and recall for class 0 but not for class 1, we require more samples for class 1 to make the model generalize well over this class too. However precision value is still closer\n",
    "\n",
    "Consider Class 0 as False and Class 1 as True.\n",
    "Here FPR is 7.792, which means the model is wrongly predicting class 0 as class 1 every 78 out of 1000 times, In any kind of system be it credit risk, fraud detection etc. this much FPR is very risky and we need to reduce it.\n",
    "\n",
    "Similary a very high FNR of 13.13% is not good as every 1 out of 8 True samples are getting rejected , this makes the model a big failure in real world sceanrios.\n",
    "\n",
    "`Conclusion/ Future Scope` : The model needs to be trained on more data and on a better variation needs to be provided in the training model, also class imabalance needs to be taken care of. To start the experiment process on the given type of dataset, this model seems good, a better data selection and hyperparameter tuning will help in getting good results.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d3a6544-1813-4e94-9700-ca4f323316b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6223845a-30ba-4156-9ab7-74bdf539fc8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
